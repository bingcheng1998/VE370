<img src="https://ws2.sinaimg.cn/large/006tNbRwly1fxhtku0vanj30qo050afg.jpg" width=320 />





# Artificial Neural Networks

## <center>VE370 Project 3</center>

























<center>Bingcheng HU</center>
<center>516021910219</center>
<center>December 7, 2018</center>

<div STYLE="page-break-after: always;"></div>
## <center>Contents</center>
[TOC]
<div STYLE="page-break-after: always;"></div>

## <center>Abstract</center>

**Key Words:** 



## 1 Introduction￼￼

The Alpha Go, which combines CNNs and reinforcement learning, has already achieved a great success [Liu]. Compared with the supervised learning approaches, the unsupervised, semi-supervised and reinforcement-learning approaches, capable of overcoming the computational limitations, deserve further investigation.

<table rules=none frame=void><tr>
    <td><img src=https://ws3.sinaimg.cn/large/006tNbRwly1fxrlweadzsj30g70ds40g.jpg border=0><center>(a)</center></td>
<td><img src=https://ws1.sinaimg.cn/large/006tNbRwly1fxrlxeg9g3j30fb0aqdgd.jpg border=0><center>
    (b)</center></td>
</tr></table>


<center>Fig. 4. Biological model of neuron(a) and architecture of Neural Network with hidden layers(b) [Yadav]</center>

## 2 Background 







![image-20181201215616400](https://ws4.sinaimg.cn/large/006tNbRwly1fxrl8co4ecj31920dujtz.jpg)

<center>Fig. 1. Schematic structure of CNNs [Liu]</center>



![image-20181201215829885](https://ws2.sinaimg.cn/large/006tNbRwly1fxrlakbf1oj318e0j8dhg.jpg)

<center>Fig. 2. Conceptual structure of CNNs Convolution [Liu]</center>

## 3 Applications

### 1. Speech Recognition

![image-20181201215934244](https://ws2.sinaimg.cn/large/006tNbRwly1fxrlbnzdlcj31as0go40w.jpg)

<center>Fig. 3. Speech recognition system architecture [Liu]</center>

### 2. Computer Vision and Pattern Recognition



![image-20181201220453052](https://ws3.sinaimg.cn/large/006tNbRwly1fxrlh8uv96j31ds0ha4j7.jpg)

<center>Fig. 4. Computer Vision and Pattern Recognition Usage [Kendall]</center>



### 3. Playing board games

![image-20181201220827456](https://ws2.sinaimg.cn/large/006tNbRwly1fxrlkxfv95j314y0cswl3.jpg)

<center>Fig. 4. Blue player wins a Tic-Tac-Toe in Big Well, and the whole game [Chen]</center>



### 4. Predicting game outcomes in Dota 2



##  4 Topics for future research

Some related topics for future research are listed as follows.

• **Design of deep models to learn from fewer training data:** With the development of big data analysis, deep learning have been used for scenarios where massive amounts of unsupervised data are involved. As an efficient tool for big data analysis, the deep learning technique have achieved great success with huge amounts of unlabeled training data. However, when only a limited amount of training data is available, more powerful models are required to achieve an enhanced learning ability. It is therefore of great significance to consider how to design deep models to learn from fewer training data, especially for speech and visual recognition systems.

• **Ues of optimization algorithms to adjust the network parameters:** The method to adjust the parameters in machine learning algorithms is an emerging topic in computer science. In DNNs, a large number of parameters need to be adjusted. Moreover, with an increasing number of hidden nodes, the algorithm is more likely get trapped in the local optimum. Optimization techniques, such as the PSO [172], are therefore required to avoid this problem. The proposed training algorithm should be able to extract the features automatically and reduce the loss of information so as to mitigate both the curse of dimensionality and the local optimum.

• **Applications of unsupervised, semi-supervised and reinforcement-learning approaches to DNNs for com- plex systems:** As mentioned previously, deep learning techniques have not brought satisfactory results in NLP. With the development of deep unsupervised learning and deep reinforcement learning, we have more alternatives to train the DNNs for complex systems. The Alpha Go, which combines CNNs and reinforcement learning, has already achieved a great success. Compared with the supervised learning approaches, the unsupervised, semi-supervised and reinforcement-learning approaches, capable of overcoming the computational limitations, deserve further investigation.

• **Implementation of deep learning algorithms on mobile devices:** It should be noted that deep learning approaches, especially CNNs, usually require great computational burden. Recently, the idea of deep learning chips has emerged and attracted great research attention. A chip for neural networks implementation has already been presented by MIT researchers. This chip is 10 times as efficient as a mobile GPU, which means that we can run AI algorithms in mobile devices with lower power consumption. Additionally, Stanford has started the project aiming at optimizing the CPU for deep learning. This area can bring numerous benefits for both industries and academia.

• **Analysis of the stability of deep neural networks:** Dynamic neural networks have been widely used to solve optimization problems and applied to many engineering applications. Nowadays, the stability analysis of deep neural networks has become a hot research topic because of the numerous benefits for industries. It should be pointed out that, so far, there have been a multitude of research results on the stability analysis, stabilization and synchronization problems for various types of systems and networks in the literature, see [64], [67], [68], [102], [143], [163], [168], [174] for some recent publications. By utilizing these exploited techniques, we can further deal with the corresponding issues including stability analysis, synchronization and state estimation for deep neural networks.

• **Applications of deep neural networks in nonlinear networked control systems (NCSs):** Neural networks have been extensively used in control engineering and signal processing to approximate the nonlinear systems. On the other hand, up to now, the NCSs have been widely investigated and considerable results have been reported in the literature, see [21], [65], [69], [103], [104], [106]–[109], [142], [169], [170], among which the networked control systems under consideration are either linear or nonlinear with relative simple forms. Thus, it is natural to apply the deep neural networks to approximate the nonlinear NCSs with complicated dynamics to obtain better control/filtering performances.

• Design of deep models to learn from fewer training data: When only a limited amount of training data is available, more powerful models are required to achieve an enhanced learning ability. It is therefore of great significance to consider how to design deep models to learn from fewer training data, especially for speech and visual recognition systems.

• Ues of optimization algorithms to adjust the network parameters: The method to adjust the parameters in machine learning algorithms is an emerging topic in computer science. In DNNs, a large number of parameters need to be adjusted. Moreover, with an increasing number of hidden nodes, the algorithm is more likely get trapped in the local optimum.  [172]

• Applications of unsupervised, semi-supervised and reinforcement-learning approaches to DNNs for com- plex systems: Deep learning techniques have not brought satisfactory results in NLP. With the development of deep unsupervised learning and deep reinforcement learning, we have more alternatives to train the DNNs for complex systems. 

• Implementation of deep learning algorithms on mobile devices: It should be noted that deep learning approaches, especially CNNs, usually require great computational burden. Recently, the idea of deep learning chips has emerged and attracted great research attention. A chip for neural networks implementation has already been presented by MIT researchers. This chip is 10 times as efficient as a mobile GPU, which means that we can run AI algorithms in mobile devices with lower power consumption [Liu]. 

• Analysis of the stability of deep neural networks: Dynamic neural networks have been widely used to solve optimization problems and applied to many engineering applications. Nowadays, the stability analysis of deep neural networks has become a hot research topic because of the numerous benefits for industries [64].

• Applications of deep neural networks in nonlinear networked control systems (NCSs): Neural networks have been extensively used in control engineering and signal processing to approximate the nonlinear systems. On the other hand, up to now, the NCSs have been widely investigated [21]. It is natural to apply the deep neural networks to approximate the nonlinear NCSs with complicated dynamics to obtain better control/filtering performances.

## 5 Discussion

## 6 Conclusion

<div STYLE="page-break-after: always;"></div>

## <center>References</center>

[1]  Kubat, M. (2015). Artificial neural networks. In *An Introduction to Machine Learning* (pp. 91-111). Springer, Cham.

[2]  Klerfors, D., & Huston, T. L. (1998). Artificial neural networks. *St. Louis University, St. Louis, Mo*.

[Liu] Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., & Alsaadi, F. E. (2017). A survey of deep neural network architectures and their applications. *Neurocomputing*, *234*, 11-26.

[4]  Widin, V., & Adler, J. (2017). On using Artificial Neural Network models to predict game outcomes in Dota 2.

[Yadav]  Yadav, A., & Sahu, K. (2017). WIND FORECASTING USING ARTIFICIAL NEURAL NETWORKS: A SURVEY AND TAXONOMY. *International Journal of Research In Science & Engineering*, *3*.

[Chen] Chen, W. (2017). Using Neural Network and Monte-Carlo Tree Search to Play the Game TEN.

[Kendall] Kendall, A., & Gal, Y. (2017). What uncertainties do we need in bayesian deep learning for computer vision?. In Advances in neural information processing systems (pp. 5574-5584).



